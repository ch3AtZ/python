{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/dhruvbharara/Downloads/stack-overflow-developer-survey-2019 (1)/survey_results_public_final.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape) #prints the rows and columns of dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_df = pd.read_csv('/Users/dhruvbharara/Downloads/stack-overflow-developer-survey-2023/survey_results_schema_final.csv')\n",
    "print(schema_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(10) #gives the output of first ten rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(schema_df['qid']) #printing only the specified column  ,,,, this also a series \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.Age) #another way to print a column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[['Respondent','MainBranch']])  #accessign multiple columns in a single row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df.columns) #getting the names of all the columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[0])  #getting the data of a specififc row\n",
    "\n",
    "print(df.iloc[0,1]) #getting the data of row 0 to 1 \n",
    "\n",
    "print(df.iloc[[0,1],2]) #getting the  data of row 0 to 1 with colunn 2 only as an attribute \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[[0,10],1]) #getting the data of row 0 to 10 with column 1 only as an attribute\n",
    "\n",
    "print(df.loc[[0,1]]) #loc is also used to get data  and also used with combination of attribute\n",
    "\n",
    "print(df.loc[[1,2],'MainBranch']) #in loc we need to specify the labelo only if kept empty it will give a key error\n",
    "\n",
    "print(df.loc[1:20,['MainBranch','Employment']]) #1:20 infers to print access data value from rows 1 to 20\n",
    "\n",
    "print(df['WorkPlan'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[1:20 , 'Respondent':'Age1stCode']) #value of rows 1 to 20 along with attributes from responseID to learncode \n",
    "\n",
    "df.set_index('Age', inplace = True) #to set a column as an index , inplace is used to carry over those changes meaning making the changes permanent \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.index)\n",
    "\n",
    "df.reset_index(inplace=True) #reseting the index \n",
    "\n",
    "print(schema_df)\n",
    "\n",
    "print(schema_df.sort_index(ascending=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#took sample data to work on some commands\n",
    "sample_Data = {'first':['Dhruv' , 'Vraj' , 'Sanidhya ' , 'john'] , 'last':['Bharara' , 'Shah' , 'Sarda' , 'dane']  , 'email':['dhruvbharara2@gmail.com' , 'vrajshah09@gmail.com' , 'sardasandy20@gmail.com' , 'johndane@gmail.com']}\n",
    "\n",
    "sd = pd.DataFrame(sample_Data)\n",
    "\n",
    "print(sd)\n",
    "\n",
    "filt1 = (sd['first'] == 'Dhruv') #to check if the row matches or not , if matches then return true and not return false \n",
    "\n",
    "print(filt1)\n",
    "print(sd[filt1]) #will return the data frame with the filter \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(df['ConvertedComp'])\n",
    "\n",
    "high_salary = (df['ConvertedComp']>70000)\n",
    "\n",
    "print(df.loc[high_salary]) #using filter for printing salaries more than 70000\n",
    "\n",
    "print(df.loc[high_salary,['Country' , 'LanguageWorkedWith' , 'ConvertedComp']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fresher = (df['YearsCode'] > str(3))\n",
    "print(df.loc[fresher , ['ConvertedComp' , 'Respondent','YearsCode']])\n",
    "\n",
    "filt2 = df['LanguageWorkedWith'].str.contains('Python' , na = False)\n",
    "print(df.loc[filt2,'LanguageWorkedWith'])#running with filter to print the rows with python as a language worked with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#again working with the sample data created before\n",
    "sd = pd.DataFrame(sample_Data)\n",
    "print(sd)\n",
    "\n",
    "sd.columns = ['first_name ' , 'last_name' , 'email'] #just changing the names of the column..\n",
    "sd.columns = sd.columns.str.replace('email' , 'email_id') #replacing the columns names with some another name , first argument is old column name and second argument is new column name , works with anything\n",
    "\n",
    "sd.columns = [x.upper() for x in sd.columns ] #making the column names in uppercase \n",
    "\n",
    "sd.columns = [x.lower() for x in sd.columns] #making the column names in lowercase \n",
    "\n",
    "\n",
    "print(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sd.loc[2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.loc[3,['last' , 'email']] = ['doe' , 'johndoe@gmail.com'] #used for updating a row in the column , columns need to specifed first "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.loc[3,['last']] = ['Doe']\n",
    "sd.loc[3,['first']] = ['John'] #updating the rows again \n",
    "print(sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd['email'] = sd['email'].str.upper() #or run sd.email.str.upper()\n",
    "sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd['email'] = sd['email'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def email_upper(email):    #creating functions and pandas together \n",
    "    return sd.email.str.upper()\n",
    "    \n",
    "\n",
    "email_upper(sd.email)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.map(len)  # can also use sd.applymap(len) , map method only works on series \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.loc[0 , ['first']] = ['pritesh']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd.drop(index=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_Data2 = {'first':['dhruv','pritesh','sarthak'] , 'age':['20','21','22'] ,'last':['bharara','panda','singh'] }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd2 = pd.DataFrame(sample_Data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd2.sort_values(by='last',ascending=False) #sorting on the basis of last name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd2.sort_values(by=['last','age'],ascending=False) #sorting on the basis of last first and then age , ascending order is true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(['ConvertedComp','Country'],ascending=[True,False],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ConvertedComp'].nlargest(10) #gives the 10 largest values of the attribute "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.nlargest(10,['ConvertedComp','Age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampl = pd.read_excel('/Users/dhruvbharara/Downloads/TEST2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampl.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ConvertedComp'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['ConvertedComp'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Hobbyist'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Country'].value_counts()\n",
    "df['SocialMedia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SocialMedia'].value_counts(normalize=True) #this breaks down the data by percentage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup = df.groupby(['Country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup.get_group('United States') #data is displayed only of where country = United States"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt4 = df['Country']=='United States' #using filter is only useful when u want a data for a specific input...groupby is more useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[filt4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.groupby(['Country','SocialMedia'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[filt4]['SocialMedia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup['SocialMedia'].value_counts().head(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "afg = df['Country'] == 'Afghanistan'\n",
    "usa = df['Country'] == 'United States'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[afg]['SocialMedia'].str.contains('Reddit').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[afg]['SocialMedia'].str.contains('Reddit')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[6391,['SocialMedia','Country']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[usa]['SocialMedia'].str.contains('Reddit').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup['SocialMedia'].value_counts().loc['China']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup['SocialMedia'].value_counts().loc['Afghanistan']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup['ConvertedComp'].median().loc['India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup['ConvertedComp'].agg(['median','mean']).loc['India']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[usa]['LanguageWorkedWith'].str.contains('Python').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[usa]['LanguageWorkedWith'].str.contains('Python').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryrespondents = df['Country'].value_counts()\n",
    "countryrespondents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup['LanguageWorkedWith'].apply(lambda x : x.str.contains('')).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LanguageWorkedWith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup['LanguageWorkedWith'].value_counts().loc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = df['Country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup['LanguageWorkedWith'].apply(lambda y : y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup['SocialMedia'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup['LanguageWorkedWith'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv('/Users/dhruvbharara/Downloads/stack-overflow-developer-survey-2023 (1) 2/survey_results_public.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['LanguageHaveWorkedWith'].apply(lambda x : x.str.contains('Python'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['LanguageWorkedWith'].apply(lambda x : x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['LanguageHaveWorkedWith'].astype(str).apply(lambda x: 'Python' in x).value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "countr = df2.groupby('Country')\n",
    "countr['SurveyEase'].apply(lambda x: x.str.contains('Easy').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filt5 = df2['Country'] == 'India'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.loc[filt5]['SurveyEase'].str.contains('Easy').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup2 = df2.groupby('Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup2['LanguageHaveWorkedWith'].apply(lambda x : x.str.contains('Python')).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup['LanguageWorkedWith'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup2['LanguageHaveWorkedWith'].apply(lambda x : x.str.contains('Python').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countrygroup['LanguageWorkedWith'].apply(lambda x : x.str.contains('Python').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SurveyEase']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['SurveyEase'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryrespondents2 = df['Country'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryusingpython2 = countrygroup['LanguageWorkedWith'].apply(lambda x : x.str.contains('Python').sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2 = pd.concat([countryrespondents2,countryusingpython2],axis='columns',sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OfficeStackSyncHaveWorkedWith = df2['OfficeStackSyncHaveWorkedWith'].astype(str).apply(lambda x: 'Discord' in x).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['OfficeStackSyncHaveWorkedWith'] = df2['OfficeStackSyncHaveWorkedWith'].fillna('none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['OfficeStackSyncHaveWorkedWith']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OfficeStackSyncHaveWorkedWith"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OfficeStackSyncHaveWorkedWith2 = df2.groupby('OfficeStackSyncHaveWorkedWith')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryres = df2.groupby('Country')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['OfficeStackSyncHaveWorkedWith'] = df2['OfficeStackSyncHaveWorkedWith']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['OfficeStackSyncHaveWorkedWith'].apply(lambda x: 'Discord' in x)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "countryres['OfficeStackSyncHaveWorkedWith'].apply(lambda x: x.str.contains('Discord').value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(countryres['OfficeStackSyncHaveWorkedWith'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_Data3 = {'first':['Dhruv' , 'Vraj' , 'Sanidhya ' , 'john' , '' , 'raj'] , 'last':['Bharara' , 'Shah' , 'Sarda' , 'dane' 'shukla' , 'meena']  , 'email':['dhruvbharara2@gmail.com' , 'vrajshah09@gmail.com' , 'sardasandy20@gmail.com' , 'johndane@gmail.com' , '' , ''] , 'age':[18,17,34,22]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_Data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = pd.read_csv('/Users/dhruvbharara/Downloads/sample1.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.dropna() #prints only those rows which dont have any missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.dropna(axis = 'index' ,how='any')  #if axis = index then those values are dropped in which row has a missing value , how is by default set to any. drop rows with any missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.dropna(axis = 'index' ,how='all') #rows which have all missing values are dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.dropna(axis='columns' , how='any') #checks the columns for null values , if any  null value is found in the column it is dropped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.dropna(axis='index', how='any' , subset= ['Email ']) #this drops rows based on the column email , if any value in the email column is null it drops it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.dropna(axis='index', how='any' , subset= ['EXPERIENCE','Email ']) #drop where email and experience column is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.replace('','0',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.fillna('MISSING') #filling nan values with something "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5.fillna(0, inplace=True) #filling nan values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5['AGE'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_Data6 = {'name':['Dhruv' , 'Pritesh' , 'Advaith' , 'Sarthak' , 'Missing'] , 'age':['19','20','21','20','NA']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd6 = pd.DataFrame(sample_Data6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd6.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd6['age'].astype(float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd6['age'].astype(float).apply(lambda x : x >=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd6['age'] = sd6['age'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd6['age']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd6['age'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "sd6.replace('Missing',np.nan , inplace=True)\n",
    "sd6.replace('NA' , np.nan , inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd6.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_vals = ['NaN']\n",
    "df['YearsCode'].replace('Less than 1 year','1',inplace=False)\n",
    "df['YearsCode'].replace('More than 50 years','50',inplace=False)\n",
    "df['YearsCode'].fillna(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearsCode'] = df['YearsCode'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearsCode'].mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearsCode'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['YearsCode'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2c/m7b9y7bj78v2_ry5dp9j_cdh0000gn/T/ipykernel_5427/3436934387.py:3: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  ethfile2 = pd.read_csv('/Users/dhruvbharara/Downloads/archive (4)/ETH_1H.csv' , parse_dates=['Date'] , )\n"
     ]
    }
   ],
   "source": [
    "ethfile = pd.read_csv('/Users/dhruvbharara/Downloads/archive (4)/ETH_day.csv')\n",
    "d_parser = lambda x : pd.to_datetime.strptime('')\n",
    "ethfile2 = pd.read_csv('/Users/dhruvbharara/Downloads/archive (4)/ETH_1H.csv' , parse_dates=['Date'] , )\n",
    "edf= pd.DataFrame(ethfile)\n",
    "edf2 = pd.DataFrame(ethfile2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unix Timestamp</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.449700e+04</td>\n",
       "      <td>34497</td>\n",
       "      <td>34497.000000</td>\n",
       "      <td>34497.000000</td>\n",
       "      <td>34497.000000</td>\n",
       "      <td>34497.000000</td>\n",
       "      <td>34497.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.147761e+11</td>\n",
       "      <td>2018-04-28 06:07:19.238194688</td>\n",
       "      <td>239.172160</td>\n",
       "      <td>240.988877</td>\n",
       "      <td>237.142926</td>\n",
       "      <td>239.176415</td>\n",
       "      <td>1563.625471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.462799e+09</td>\n",
       "      <td>2016-01-06 00:00:00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.150000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.100000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.493845e+09</td>\n",
       "      <td>2017-05-03 21:00:00</td>\n",
       "      <td>81.020000</td>\n",
       "      <td>82.120000</td>\n",
       "      <td>79.980000</td>\n",
       "      <td>81.020000</td>\n",
       "      <td>101.092334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.524892e+09</td>\n",
       "      <td>2018-04-28 05:00:00</td>\n",
       "      <td>181.870000</td>\n",
       "      <td>182.770000</td>\n",
       "      <td>180.820000</td>\n",
       "      <td>181.870000</td>\n",
       "      <td>444.684817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.555940e+12</td>\n",
       "      <td>2019-04-22 13:00:00</td>\n",
       "      <td>298.070000</td>\n",
       "      <td>299.920000</td>\n",
       "      <td>296.380000</td>\n",
       "      <td>298.070000</td>\n",
       "      <td>1508.711881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.587000e+12</td>\n",
       "      <td>2020-12-04 23:00:00</td>\n",
       "      <td>1417.540000</td>\n",
       "      <td>1420.010000</td>\n",
       "      <td>1388.990000</td>\n",
       "      <td>1417.540000</td>\n",
       "      <td>903102.685700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7.758756e+11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>237.205512</td>\n",
       "      <td>239.468230</td>\n",
       "      <td>234.532649</td>\n",
       "      <td>237.202348</td>\n",
       "      <td>7003.461234</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unix Timestamp                           Date          Open  \\\n",
       "count    3.449700e+04                          34497  34497.000000   \n",
       "mean     7.147761e+11  2018-04-28 06:07:19.238194688    239.172160   \n",
       "min      1.462799e+09            2016-01-06 00:00:00      0.000000   \n",
       "25%      1.493845e+09            2017-05-03 21:00:00     81.020000   \n",
       "50%      1.524892e+09            2018-04-28 05:00:00    181.870000   \n",
       "75%      1.555940e+12            2019-04-22 13:00:00    298.070000   \n",
       "max      1.587000e+12            2020-12-04 23:00:00   1417.540000   \n",
       "std      7.758756e+11                            NaN    237.205512   \n",
       "\n",
       "               High           Low         Close         Volume  \n",
       "count  34497.000000  34497.000000  34497.000000   34497.000000  \n",
       "mean     240.988877    237.142926    239.176415    1563.625471  \n",
       "min        6.150000      0.000000      6.100000       0.000000  \n",
       "25%       82.120000     79.980000     81.020000     101.092334  \n",
       "50%      182.770000    180.820000    181.870000     444.684817  \n",
       "75%      299.920000    296.380000    298.070000    1508.711881  \n",
       "max     1420.010000   1388.990000   1417.540000  903102.685700  \n",
       "std      239.468230    234.532649    237.202348    7003.461234  "
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "edf2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 34497 entries, 0 to 34496\n",
      "Data columns (total 8 columns):\n",
      " #   Column          Non-Null Count  Dtype         \n",
      "---  ------          --------------  -----         \n",
      " 0   Unix Timestamp  34497 non-null  float64       \n",
      " 1   Date            34497 non-null  datetime64[ns]\n",
      " 2   Symbol          34497 non-null  object        \n",
      " 3   Open            34497 non-null  float64       \n",
      " 4   High            34497 non-null  float64       \n",
      " 5   Low             34497 non-null  float64       \n",
      " 6   Close           34497 non-null  float64       \n",
      " 7   Volume          34497 non-null  float64       \n",
      "dtypes: datetime64[ns](1), float64(6), object(1)\n",
      "memory usage: 2.1+ MB\n"
     ]
    }
   ],
   "source": [
    "edf2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dhruv</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pritesh</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Advaith</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sarthak</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      name age\n",
       "0    Dhruv  19\n",
       "1  Pritesh  20\n",
       "2  Advaith  21\n",
       "3  Sarthak  20\n",
       "4        0   0"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sd6\n",
    "out = pd.read_sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
