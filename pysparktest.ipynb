{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Practice').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.read.csv('/Users/dhruvbharara/Downloads/stack-overflow-developer-survey-2023/survey_results_schema_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.read.option('header','true').csv('/Users/dhruvbharara/Downloads/stack-overflow-developer-survey-2023/survey_results_schema_final.csv').show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.head(10)\n",
    "df_spark.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark = spark.read.csv('/Users/dhruvbharara/Downloads/stack-overflow-developer-survey-2023/survey_results_schema_final.csv',header=True,inferSchema=True)\n",
    "df_spark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.select('qname').show() #to print the values of a single column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.select('qname','question').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark['qname'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_spark.withColumn('qid+qname',df_spark['qid']+df_spark['qname']).show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = spark.read.csv('/Users/dhruvbharara/Downloads/companies.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = spark.read.csv('/Users/dhruvbharara/Downloads/sample1.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+-------+\n",
      "|    NAME|AGE|EXPERIENCE| SALARY|\n",
      "+--------+---+----------+-------+\n",
      "|   krish| 23|         2|1000000|\n",
      "|sudanshu| 34|        12|2800000|\n",
      "| priyank| 32|        10|2200000|\n",
      "|   jawal| 28|         6|1650000|\n",
      "|  mahesh| 24|         3| 560000|\n",
      "|  rajesh| 38|        12|2240000|\n",
      "|    raju| 25|         4|1256000|\n",
      "|   makol| 40|        15|4500000|\n",
      "|   dhruv| 22|         1| 850000|\n",
      "|   anmol| 22|         1| 560000|\n",
      "|     raj| 24|         2| 678000|\n",
      "|     ram| 25|         4|1350000|\n",
      "+--------+---+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.drop('experience').show() #the changes made are not permanent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.na.drop().show() #used to drop the null values in the dataset , the whole row is deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.na.drop(how='any').show() #how variable takes 2 arguments (any,all)..any means the row is dropped if any value is null "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.na.drop(how='all').show() # as all is chosen so only the row which has all the null values will be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.na.drop(how='any',thresh=3).show() #thresh means to delete the row if atleast 3(input) values are null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.na.drop(how='any',subset=['experience']).show() #subset is used to delete the row in which the column value is null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.na.fill('Missing value').show() #to replace the null value , it will only work if the column datatype is same as filling value type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.na.fill(value=0,subset=['age']).show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.filter('salary<=1000000').show() #to retrieve all columns based on information specified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.filter('salary<=1000000').select(['Name','Age']).show() #to retrieve the specified columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.filter(s['SALARY']<=1000000).show() #another way to write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s.filter((s['SALARY']>=1000000) & (s['salary']<=1500000)).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = spark.read.csv('/Users/dhruvbharara/Downloads/testspark.csv',header=True,inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.groupBy('name').sum().show() #grouped to find maximum sum of salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2.groupBy('name').max().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|Department|sum(salary)|\n",
      "+----------+-----------+\n",
      "|       fsd|      38370|\n",
      "|blockchain|      65670|\n",
      "|        it|      36600|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s2.groupBy('Department').sum().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------+\n",
      "|Department|avg(salary)|\n",
      "+----------+-----------+\n",
      "|       fsd|     9592.5|\n",
      "|blockchain|    16417.5|\n",
      "|        it|     9150.0|\n",
      "+----------+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s2.groupBy('Department').mean().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----+\n",
      "|department|count|\n",
      "+----------+-----+\n",
      "|       fsd|    4|\n",
      "|blockchain|    4|\n",
      "|        it|    4|\n",
      "+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s2.groupBy('department').count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|sum(salary)|\n",
      "+-----------+\n",
      "|     140640|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s2.agg({'salary':'sum'}).show() #using a aggregate function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+----------+-------+\n",
      "|    NAME| AGE|EXPERIENCE| SALARY|\n",
      "+--------+----+----------+-------+\n",
      "|   krish|  23|         2|1000000|\n",
      "|sudanshu|  34|        12|2800000|\n",
      "| priyank|  32|        10|2200000|\n",
      "|   jawal|  28|         6|1650000|\n",
      "|  mahesh|  24|         3| 560000|\n",
      "|  rajesh|NULL|        12|2240000|\n",
      "|    raju|  25|         4|   NULL|\n",
      "|   makol|  40|      NULL|4500000|\n",
      "|   dhruv|  22|         1| 850000|\n",
      "|    NULL|NULL|      NULL|   NULL|\n",
      "|     raj|  24|         2| 678000|\n",
      "|     ram|NULL|         4|   NULL|\n",
      "+--------+----+----------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- NAME: string (nullable = true)\n",
      " |-- AGE: integer (nullable = true)\n",
      " |-- EXPERIENCE: integer (nullable = true)\n",
      " |-- SALARY: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "s.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NAME', 'AGE', 'EXPERIENCE', 'SALARY']"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "featureassembler = VectorAssembler(inputCols=['AGE','EXPERIENCE'],outputCol=\"Independent feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = featureassembler.transform(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+---+----------+-------+-------------------+\n",
      "|    NAME|AGE|EXPERIENCE| SALARY|Independent feature|\n",
      "+--------+---+----------+-------+-------------------+\n",
      "|   krish| 23|         2|1000000|         [23.0,2.0]|\n",
      "|sudanshu| 34|        12|2800000|        [34.0,12.0]|\n",
      "| priyank| 32|        10|2200000|        [32.0,10.0]|\n",
      "|   jawal| 28|         6|1650000|         [28.0,6.0]|\n",
      "|  mahesh| 24|         3| 560000|         [24.0,3.0]|\n",
      "|  rajesh| 38|        12|2240000|        [38.0,12.0]|\n",
      "|    raju| 25|         4|1256000|         [25.0,4.0]|\n",
      "|   makol| 40|        15|4500000|        [40.0,15.0]|\n",
      "|   dhruv| 22|         1| 850000|         [22.0,1.0]|\n",
      "|   anmol| 22|         1| 560000|         [22.0,1.0]|\n",
      "|     raj| 24|         2| 678000|         [24.0,2.0]|\n",
      "|     ram| 25|         4|1350000|         [25.0,4.0]|\n",
      "+--------+---+----------+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "output.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NAME', 'AGE', 'EXPERIENCE', 'SALARY', 'Independent feature']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalized = output.select('Independent feature','SALARY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------+\n",
      "|Independent feature| SALARY|\n",
      "+-------------------+-------+\n",
      "|         [23.0,2.0]|1000000|\n",
      "|        [34.0,12.0]|2800000|\n",
      "|        [32.0,10.0]|2200000|\n",
      "|         [28.0,6.0]|1650000|\n",
      "|         [24.0,3.0]| 560000|\n",
      "|        [38.0,12.0]|2240000|\n",
      "|         [25.0,4.0]|1256000|\n",
      "|        [40.0,15.0]|4500000|\n",
      "|         [22.0,1.0]| 850000|\n",
      "|         [22.0,1.0]| 560000|\n",
      "|         [24.0,2.0]| 678000|\n",
      "|         [25.0,4.0]|1350000|\n",
      "+-------------------+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "finalized.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.regression import LinearRegression \n",
    "train_data,test_data = finalized.randomSplit([0.75,0.25])\n",
    "regressor = LinearRegression(featuresCol = 'Independent feature',labelCol =  'SALARY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98590ff4fe04c8543246b2a01debd3de3c5ca9b666f43f1fa87d5110c692004c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
